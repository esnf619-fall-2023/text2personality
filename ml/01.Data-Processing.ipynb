{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Loading and Exploring the Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b129ee10875cc9be"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   type                                              posts\n0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n1  ENTP  'I'm finding the lack of me in these posts ver...\n2  INTP  'Good one  _____   https://www.youtube.com/wat...\n3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n4  ENTJ  'You're fired.|||That's another silly misconce...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>posts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTP</td>\n      <td>'I'm finding the lack of me in these posts ver...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INTP</td>\n      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTJ</td>\n      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTJ</td>\n      <td>'You're fired.|||That's another silly misconce...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV data\n",
    "file_path = 'data/01.original/original_data.csv' \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:20:50.376800100Z",
     "start_time": "2023-10-17T23:20:49.809218400Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Break down each row with some related posts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b418de9fab3bf6d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "     type                                               post\n0    INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw\n1    INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...\n2    INFJ  enfp and intj moments  https://www.youtube.com...\n3    INFJ  What has been the most life-changing experienc...\n4    INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...\n..    ...                                                ...\n995  INTP  But either way, he'd get there by use of his N...\n996  INTP  Every edgy NTP and their mother acts on their ...\n997  INTP  it's cause you spend all your time irl ignorin...\n998  INTP  just gonna ignore all your rules.  Si - Normal...\n999  INTP  ixfj  must research si vs ni, I suck at those ...\n\n[1000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>post</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>INFJ</td>\n      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INFJ</td>\n      <td>enfp and intj moments  https://www.youtube.com...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INFJ</td>\n      <td>What has been the most life-changing experienc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>INFJ</td>\n      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>INTP</td>\n      <td>But either way, he'd get there by use of his N...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>INTP</td>\n      <td>Every edgy NTP and their mother acts on their ...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>INTP</td>\n      <td>it's cause you spend all your time irl ignorin...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>INTP</td>\n      <td>just gonna ignore all your rules.  Si - Normal...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>INTP</td>\n      <td>ixfj  must research si vs ni, I suck at those ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to split posts and preserve the unique identifier\n",
    "def split_posts(row):\n",
    "    posts = row['posts'].split('|||')\n",
    "    return pd.DataFrame({'type': row['type'], 'post': posts})\n",
    "\n",
    "# Apply the function to split posts and concatenate the results\n",
    "split_df = pd.concat(data.apply(lambda row: split_posts(row), axis=1).tolist(), ignore_index=True)\n",
    "\n",
    "# Save the split DataFrame to a new CSV file\n",
    "split_df.to_csv('split_data.csv', index=False)\n",
    "split_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:21:14.526044400Z",
     "start_time": "2023-10-17T23:21:11.827098100Z"
    }
   },
   "id": "b985476b7140da13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Cleaning the Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd9f40e744ef7399"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alireza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alireza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "   type                                               post\n0  INFJ    'http : //www.youtube.com/watch ? v=qsxhcwe3krw\n1  INFJ  http : //41.media.tumblr.com/tumblr_lfouy03pma...\n2  INFJ  enfp intj moment http : //www.youtube.com/watc...\n3  INFJ                           life-chang experi life ?\n4  INFJ  http : //www.youtube.com/watch ? v=vxzeywwrdw8...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>post</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>'http : //www.youtube.com/watch ? v=qsxhcwe3krw</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>INFJ</td>\n      <td>http : //41.media.tumblr.com/tumblr_lfouy03pma...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INFJ</td>\n      <td>enfp intj moment http : //www.youtube.com/watc...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INFJ</td>\n      <td>life-chang experi life ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>INFJ</td>\n      <td>http : //www.youtube.com/watch ? v=vxzeywwrdw8...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download NLTK resources (if not done already)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tokenization, stopwords removal, and stemming function\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "# Apply preprocessing to the 'posts' column\n",
    "split_df['post'] = split_df['post'].apply(preprocess_text)\n",
    "split_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:27:25.119782900Z",
     "start_time": "2023-10-17T23:22:33.718102200Z"
    }
   },
   "id": "3dfe68205026c667"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Remove URLs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa8eb3e3b7acdeb2"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "   type                                               post\n0  INFJ                                   http vqsxhcwekrw\n1  INFJ         http mediatumblrcomtumblrlfouypmaqarooojpg\n2  INFJ  enfp intj moment http vizlegxm sportscent top ...\n3  INFJ                              lifechang experi life\n4  INFJ        http vvxzeywwrdw http vuejamdp repeat today",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>post</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>INFJ</td>\n      <td>http vqsxhcwekrw</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>INFJ</td>\n      <td>http mediatumblrcomtumblrlfouypmaqarooojpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>INFJ</td>\n      <td>enfp intj moment http vizlegxm sportscent top ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INFJ</td>\n      <td>lifechang experi life</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>INFJ</td>\n      <td>http vvxzeywwrdw http vuejamdp repeat today</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove invalid characters and non-alphabetic words\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = remove_urls(text)\n",
    "    # Remove non-alphabetic characters and extra spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(' +', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "# Apply URL removal and text cleaning to the 'posts' column\n",
    "split_df['post'] = split_df['post'].apply(clean_text)\n",
    "split_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:28:02.733057800Z",
     "start_time": "2023-10-17T23:27:58.845870700Z"
    }
   },
   "id": "93101cfea1327253"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Remove empty posts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35c77fa94d3cd6b2"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Remove records with empty post values\n",
    "split_df = split_df[split_df['post'].str.strip() != '']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:34:06.654796800Z",
     "start_time": "2023-10-17T23:34:06.498649400Z"
    }
   },
   "id": "a3935f8e6c1b8c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Saving the processed data "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c02d76c2a21d51c"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "split_df.to_csv('data/02.processed/processed_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:34:12.089013700Z",
     "start_time": "2023-10-17T23:34:11.230568900Z"
    }
   },
   "id": "a7d51325a55683a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a72cf7fb0e30e4d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
